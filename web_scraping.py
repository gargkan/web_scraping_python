# -*- coding: utf-8 -*-
"""web_scraping.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SloVAZ1OaD06-OBQ7O2g7GT_eItlDmXX
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd

URL = "https://realpython.github.io/fake-jobs/"
page = requests.get(URL)
soup = BeautifulSoup(page.content, 'html.parser')
#print(page.text)
result = soup.find(id = "ResultsContainer")



print(result.prettify())

job_elements = result.find_all('div', class_ = 'card-content')



for job_element in job_elements:
  title_element = job_element.find('h2',class_ = 'title')
  company_element = job_element.find('h3',class_ = 'company')
  location_element = job_element.find('p',class_ = 'location')
  print(title_element, end="\n"*2)
  print(company_element, end="\n"*2)
  print(location_element, end="\n"*2)

# Extract Text From HTML Elements
for job_element in job_elements:
    title_element = job_element.find("h2", class_="title")
    company_element = job_element.find("h3", class_="company")
    location_element = job_element.find("p", class_="location")
    print(title_element.text.strip())
    print(company_element.text.strip())
    print(location_element.text.strip())
    print()

python_jobs = result.find_all("h2", string="Python")
print(python_jobs)

python_jobs = result.find_all("h2", string=lambda text: "python" in text.lower())
print(python_jobs)

python_job_elements = [h2_element.parent.parent.parent for h2_element in python_jobs]
df = pd.DataFrame()
  
for job_element in python_job_elements:
    title_element = job_element.find("h2", class_="title")
    company_element = job_element.find("h3", class_="company")
    location_element = job_element.find("p", class_="location")
    data = {'Title':[title_element.text.strip()], 'Company':[company_element.text.strip()],
            'Location':[location_element.text.strip()]}
    df = df.append(data, ignore_index=True)
#data
df
file = df.to_csv('master.csv', encoding ='utf-8', index = False)
file

